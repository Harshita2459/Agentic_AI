# -*- coding: utf-8 -*-
"""Crime_report_analysis_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EF31HVAzif1MDP7gmwHfm3qgUC90pCat
"""

import json
from typing import Dict, List, Optional
from dataclasses import dataclass
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="huggingface_hub")
import os



@dataclass
class Suspect:
    name: str
    dob: str
    father: str
    address: str
    involvement: str

@dataclass
class Witness:
    name: str
    age: int
    relation: str
    testimony: str

@dataclass
class Evidence:
    item: str
    value: float
    status: str

@dataclass
class CaseData:
    case_name: str
    date: str
    summary: str
    suspects: List[Suspect]
    weapons: List[str]
    witnesses: List[Witness]
    evidence: List[Evidence]
    investigation_team: Dict[str, str]
    status: str

class CrimeInvestigationAgent:
    def __init__(self, model_name='all-MiniLM-L6-v2', local_model_path=None):
        self.case_data = None
        self.vector_db = None
        self.text_chunks = []

        try:
            if local_model_path and os.path.exists(local_model_path):
                self.embedding_model = SentenceTransformer(local_model_path)
            else:
                os.environ["TOKENIZERS_PARALLELISM"] = "false"
                self.embedding_model = SentenceTransformer(model_name)
        except Exception as e:
            raise RuntimeError(f"Failed to load embedding model: {str(e)}")

    def load_case(self, case_file: str):
        """Load case data from JSON file"""
        with open(case_file, 'r') as f:
            data = json.load(f)

        suspects = [Suspect(**s) for s in data['suspects']]
        witnesses = [Witness(**w) for w in data['witnesses']]
        evidence = [Evidence(**e) for e in data['evidence']]

        self.case_data = CaseData(
            case_name=data['case_name'],
            date=data['date'],
            summary=data['summary'],
            suspects=suspects,
            weapons=data['weapons'],
            witnesses=witnesses,
            evidence=evidence,
            investigation_team=data['investigation_team'],
            status=data['status']
        )

        self._build_vector_db()

    def _build_vector_db(self):
        """Create vector embeddings for all case text"""
        self.text_chunks = []

        self.text_chunks.append(("summary", self.case_data.summary))

        for suspect in self.case_data.suspects:
            text = f"Suspect {suspect.name}, DOB {suspect.dob}, address {suspect.address}. {suspect.involvement}"
            self.text_chunks.append((f"suspect_{suspect.name}", text))

        for witness in self.case_data.witnesses:
            text = f"Witness {witness.name}, age {witness.age}, {witness.relation}. Testimony: {witness.testimony}"
            self.text_chunks.append((f"witness_{witness.name}", text))

        for item in self.case_data.evidence:
            text = f"Evidence: {item.item}, value ${item.value/1000:.1f}K, status: {item.status}"
            self.text_chunks.append((f"evidence_{item.item}", text))

        for weapon in self.case_data.weapons:
            self.text_chunks.append((f"weapon_{weapon[:10]}", weapon))

        texts = [chunk[1] for chunk in self.text_chunks]
        self.vector_db = self.embedding_model.encode(texts, show_progress_bar=False)

    def query(self, question: str, top_k: int = 3) -> List[str]:
        """Answer questions about the case using vector similarity"""
        if not self.case_data:
            return ["No case data loaded"]

        question_embedding = self.embedding_model.encode([question], show_progress_bar=False)

        similarities = cosine_similarity(question_embedding, self.vector_db)[0]
        top_indices = np.argsort(similarities)[-top_k:][::-1]

        answers = []
        for idx in top_indices:
            source, text = self.text_chunks[idx]
            answers.append(f"{text} (source: {source})")

        return answers

    def generate_report(self, queries: List[str]) -> Dict[str, List[str]]:
        """Generate a formatted report answering multiple queries"""
        report = {}
        for query in queries:
            report[query] = self.query(query)
        return report

if __name__ == "__main__":
    try:
        agent = CrimeInvestigationAgent()

        case_data = {
            "case_name": "Greenwood Jewelers Robbery",
            "date": "March 25, 2025",
            "summary": "Armed robbery at Greenwood Jewelers with $2.5M in stolen goods...",
            "suspects": [
                {
                    "name": "Vincent Carter",
                    "dob": "12/08/1989",
                    "father": "Richard Carter",
                    "address": "45B Elmwood Ave",
                    "involvement": "Primary suspect with prior armed robbery convictions"
                },
            ],
            "weapons": [
                "Two 9mm pistols (serial numbers filed off)",
                "Sawed-off shotgun (12-gauge)",
                "Crowbar with DNA traces"
            ],
            "witnesses": [
                {
                    "name": "Daniel Mitchell",
                    "age": 42,
                    "relation": "Store Manager",
                    "testimony": "The tallest suspect had a deep Eastern European accent..."
                },
            ],
            "evidence": [
                {
                    "item": "Cash from SUV",
                    "value": 320000,
                    "status": "Recovered"
                },
            ],
            "investigation_team": {
                "Lead Investigator": "Detective Inspector Laura Hayes",
                "Forensic Lead": "Dr. Alan Whitaker"
            },
            "status": "Active"
        }

        with open('temp_case.json', 'w') as f:
            json.dump(case_data, f)

        agent.load_case('temp_case.json')

        queries = [
            "What distinguishing physical features were reported by witnesses?",
            "What is the connection between Sophia Reynolds and the crime scene?",
            "What ballistic evidence was recovered?",
            "How much of the stolen property remains unrecovered?",
            "What international coordination has been initiated?"
        ]

        report = agent.generate_report(queries)

        for question, answers in report.items():
            print(f"Q: {question}")
            for ans in answers:
                print(f"- {ans}")
            print()

    except Exception as e:
        print(f"Error occurred: {str(e)}")